{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import pathlib\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"-1\"    \n",
    "import time\n",
    "import sys\n",
    "import sklearn\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import losses, optimizers\n",
    "import tensorflow as tf\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置参数\n",
    "data_dir = \"pokemen\"\n",
    "train_txt = os.path.join(data_dir, \"list_train_shuffle.txt\")\n",
    "val_txt = os.path.join(data_dir, \"list_val_shuffle.txt\")\n",
    "train_dir = data_dir\n",
    "val_dir = data_dir\n",
    "\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "height = 224\n",
    "width = 224\n",
    "channels = 3\n",
    "BATCH_SIZE = 4\n",
    "num_classes = 5\n",
    "base_lr = 1e-2\n",
    "gamma = 0.1\n",
    "momentum = 0.9\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 读图片路径 && 保存路径和标签到文件\n",
    "1. 读文件夹\n",
    "2. 遍历文件夹内的所有图形\n",
    "3. 保存到文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_imageset_to_txt(read_folder, save_path):\n",
    "    def format_txt_lines(path, index):\n",
    "        return ''.join(path + \" \" + str(index) + \"\\n\")\n",
    "    \n",
    "    # 输入判断\n",
    "    if not os.path.exists(read_folder):\n",
    "        raise ValueError(\"can not find folder:\" + read_folder)\n",
    "    if os.path.exists(save_path):\n",
    "        os.remove(save_path)\n",
    "    \n",
    "    # 读所有文件夹\n",
    "    dirs = os.listdir(read_folder)\n",
    "    dirs = filter(lambda f : os.path.isdir(os.path.join(read_folder, f)), dirs)\n",
    "    \n",
    "    for i, sub_dir in enumerate(list(dirs)):\n",
    "        # 读文件夹图像\n",
    "        images_path = glob.glob( os.path.join(read_folder, sub_dir, \"*.??g\") )\n",
    "        labels = [i] * len(images_path)\n",
    "        labels_images = list(map(format_txt_lines, images_path, labels))\n",
    "        with open(save_path, 'a') as f:\n",
    "            for label in labels_images:\n",
    "                f.write(label)\n",
    "        \n",
    "        print(\"folder {} have {} images.\".format(sub_dir, len(images_path)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder bulbasaur have 233 images.\n",
      "folder charmander have 236 images.\n",
      "folder mewtwo have 237 images.\n",
      "folder pikachu have 232 images.\n",
      "folder squirtle have 221 images.\n"
     ]
    }
   ],
   "source": [
    "save_path = \"./list_train.txt\"\n",
    "read_imageset_to_txt(data_dir, save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF载入图像数据\n",
    "1. 读入数据集\n",
    "2. 解析数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_load_and_prase_data(train_txt, val_txt = None):\n",
    "    \"\"\"\n",
    "        读入数据集，并返回可使用的tf对象\n",
    "        \n",
    "        input:\n",
    "            train_txt: 训练集数据\n",
    "            val_txt：验证集数据\n",
    "        \n",
    "        return：\n",
    "            train_ds, val_ds\n",
    "    \"\"\"\n",
    "    def read_lines_from_txt(txt):\n",
    "        lines = []\n",
    "        with open(txt, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "        return lines\n",
    "    \n",
    "    def split_dataset(dataset, prop = 0.05):\n",
    "        train_data = []\n",
    "        val_data = []\n",
    "        for data in dataset:\n",
    "            if random.random() > prop:\n",
    "                train_data.append(data)\n",
    "            else:\n",
    "                val_data.append(data)\n",
    "        return train_data, val_data\n",
    "    \n",
    "    def tf_read_and_prase_data(dataset):\n",
    "        \"\"\"\n",
    "            input:\n",
    "                dataset: [lines, lines, lines, ...]\n",
    "            \n",
    "            output:\n",
    "                ds\n",
    "        \"\"\"\n",
    "        def preprocess_image(image):\n",
    "            image = tf.image.decode_jpeg(image, channels = channels)\n",
    "            image = tf.image.resize(image, [height, width])\n",
    "            image /= 255.0  # normalize to [0,1] range\n",
    "            return image\n",
    "\n",
    "        def load_and_preprocess_image(path):\n",
    "            image = tf.io.read_file(path)\n",
    "            return preprocess_image(image)\n",
    "        \n",
    "        # 分割数据\n",
    "        images_path = []\n",
    "        labels = []\n",
    "        for data in dataset:\n",
    "            if len(data.strip().split(\" \")[1:]) != 0:\n",
    "                images_path.append(data.strip().split(\" \")[0])\n",
    "                labels.append(int(data.strip().split(\" \")[1]))\n",
    "\n",
    "        # 读取数据\n",
    "        path_ds = tf.data.Dataset.from_tensor_slices(images_path)\n",
    "        image_ds = path_ds.map(load_and_preprocess_image)\n",
    "        label_ds = tf.data.Dataset.from_tensor_slices(tf.cast(labels, tf.int64))\n",
    "        \n",
    "        # 解析数据\n",
    "        return tf.data.Dataset.zip((image_ds, label_ds))\n",
    "        \n",
    "    \n",
    "    # 输入判断\n",
    "    if not os.path.exists(train_txt):\n",
    "        raise ValueError(\"can not find the file:\" + train_txt)             \n",
    "    if val_txt is not None and not os.path.exists(val_txt):\n",
    "        raise ValueError(\"can not find the file:\" + val_txt)\n",
    "    \n",
    "    \n",
    "    # 区分 && 打乱数据集\n",
    "    if val_txt is not None:\n",
    "        train_path_label = read_lines_from_txt(train_txt)\n",
    "        val_path_label = read_lines_from_txt(val_txt)\n",
    "    else:\n",
    "        train_data = read_lines_from_txt(train_txt)\n",
    "        train_path_label, val_path_label = split_dataset(train_data)\n",
    "    \n",
    "    num_train = len(train_path_label)\n",
    "    num_valid = len(val_path_label)\n",
    "    print(\"numbers of train dataset:{}, numbers of val dataset:{}\".format(num_train, num_valid))\n",
    "    \n",
    "    # 读入 && 解析数据\n",
    "    train_ds = tf_read_and_prase_data(train_path_label)\n",
    "    val_ds = tf_read_and_prase_data(val_path_label)\n",
    "    \n",
    "    return train_ds, num_train, val_ds, num_valid\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_load_and_prase_data_v2(train_txt, val_txt = None):\n",
    "    \"\"\"\n",
    "        读入数据集，并返回可使用的tf对象\n",
    "        \n",
    "        input:\n",
    "            train_txt: 训练集数据\n",
    "            val_txt：验证集数据\n",
    "        \n",
    "        return：\n",
    "            train_ds, val_ds\n",
    "    \"\"\"\n",
    "    def read_lines_from_txt(txt):\n",
    "        lines = []\n",
    "        with open(txt, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "        return lines\n",
    "    \n",
    "    def split_dataset(dataset, prop = 0.05):\n",
    "        train_data = []\n",
    "        val_data = []\n",
    "        for data in dataset:\n",
    "            if random.random() > prop:\n",
    "                train_data.append(data)\n",
    "            else:\n",
    "                val_data.append(data)\n",
    "        return train_data, val_data\n",
    "    \n",
    "    def tf_read_and_prase_data(dataset):\n",
    "        \"\"\"\n",
    "            input:\n",
    "                dataset: [lines, lines, lines, ...]\n",
    "            \n",
    "            output:\n",
    "                ds\n",
    "        \"\"\"\n",
    "        def preprocess_image(image):\n",
    "            image = tf.image.decode_jpeg(image, channels = channels)\n",
    "            image = tf.image.resize(image, [height, width])\n",
    "            image /= 255.0  # normalize to [0,1] range\n",
    "            return image\n",
    "\n",
    "        def load_and_preprocess_image(path):\n",
    "            image = tf.io.read_file(path)\n",
    "            return preprocess_image(image)\n",
    "        \n",
    "        # 分割数据\n",
    "        images_path = []\n",
    "        labels = []\n",
    "        for data in dataset:\n",
    "            if len(data.strip().split(\" \")[1:]) != 0:\n",
    "                images_path.append(data.strip().split(\" \")[0])\n",
    "                labels.append(int(data.strip().split(\" \")[1]))\n",
    "\n",
    "        # 读取数据\n",
    "        ds = tf.data.Dataset.from_tensor_slices((images_path, labels))\n",
    "        \n",
    "        # 解析数据\n",
    "        return ds\n",
    "        \n",
    "    \n",
    "    # 输入判断\n",
    "    if not os.path.exists(train_txt):\n",
    "        raise ValueError(\"can not find the file:\" + train_txt)             \n",
    "    if val_txt is not None and not os.path.exists(val_txt):\n",
    "        raise ValueError(\"can not find the file:\" + val_txt)\n",
    "    \n",
    "    \n",
    "    # 区分 && 打乱数据集\n",
    "    if val_txt is not None:\n",
    "        train_path_label = read_lines_from_txt(train_txt)\n",
    "        val_path_label = read_lines_from_txt(val_txt)\n",
    "    else:\n",
    "        train_data = read_lines_from_txt(train_txt)\n",
    "        train_path_label, val_path_label = split_dataset(train_data)\n",
    "    \n",
    "    num_train = len(train_path_label)\n",
    "    num_valid = len(val_path_label)\n",
    "    print(\"numbers of train dataset:{}, numbers of val dataset:{}\".format(num_train, num_valid))\n",
    "    \n",
    "    # 读入 && 解析数据\n",
    "    train_ds = tf_read_and_prase_data(train_path_label)\n",
    "    val_ds = tf_read_and_prase_data(val_path_label)\n",
    "    \n",
    "    return train_ds, num_train, val_ds, num_valid\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numbers of train dataset:1091, numbers of val dataset:68\n"
     ]
    }
   ],
   "source": [
    "txt = \"./list_train.txt\"\n",
    "train_origin_ds, num_train, val_origin_ds, num_valid = tf_load_and_prase_data_v2(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_shuffle_data(dataset, buffer_size, batch_size):\n",
    "    def normalize(x, mean=tf.constant([0.485, 0.456, 0.406]), std= tf.constant([0.229, 0.224, 0.225])):\n",
    "        # 标准化\n",
    "        # x: [224, 224, 3]\n",
    "        # mean: [224, 224, 3], std: [3]\n",
    "        x = (x - mean)/std\n",
    "        return x\n",
    "\n",
    "    def preprocess(x,y):\n",
    "        # x: 图片的路径，y：图片的数字编码\n",
    "        x = tf.io.read_file(x)\n",
    "        x = tf.image.decode_jpeg(x, channels=3) # RGBA\n",
    "        x = tf.image.resize(x, [244, 244])\n",
    "\n",
    "        x = tf.image.random_flip_left_right(x)\n",
    "        x = tf.image.random_flip_up_down(x)\n",
    "        x = tf.image.random_crop(x, [224,224,3])\n",
    "\n",
    "        # x: [0,255]=> -1~1\n",
    "        x = tf.cast(x, dtype=tf.float32) / 255.\n",
    "        x = normalize(x)\n",
    "        y = tf.convert_to_tensor(y)\n",
    "        y = tf.one_hot(y, depth=5)\n",
    "\n",
    "        return x, y\n",
    "    \n",
    "    ds = dataset.shuffle(buffer_size=buffer_size)\n",
    "    ds = ds.repeat()\n",
    "    ds = ds.map(preprocess).batch(batch_size)\n",
    "    # 当模型在训练的时候，`prefetch` 使数据集在后台取得 batch。\n",
    "    ds = ds.prefetch(buffer_size = tf.data.experimental.AUTOTUNE)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = tf_shuffle_data(train_origin_ds, num_train, BATCH_SIZE)\n",
    "val_ds = tf_shuffle_data(val_origin_ds, num_valid, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建模型\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Conv2D(64, (3,3), padding = 'same', activation = 'relu', strides = 2, input_shape = (height, width, channels)),\n",
    "    keras.layers.Conv2D(64, (3,3), padding = 'same', activation = 'relu', strides = 2),\n",
    "    keras.layers.Conv2D(128, (3,3), padding = 'same', activation = 'relu', strides = 2),\n",
    "    keras.layers.Conv2D(128, (3,3), padding = 'same', activation = 'relu', strides = 2),\n",
    "    keras.layers.Conv2D(256, (3,3), padding = 'same', activation = 'relu', strides = 2),\n",
    "    keras.layers.AveragePooling2D((7,7)),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(num_classes, activation = 'softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 112, 112, 64)      1792      \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 56, 56, 64)        36928     \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 28, 28, 128)       73856     \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 14, 14, 128)       147584    \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 7, 7, 256)         295168    \n",
      "_________________________________________________________________\n",
      "average_pooling2d (AveragePo (None, 1, 1, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 5)                 1285      \n",
      "=================================================================\n",
      "Total params: 556,613\n",
      "Trainable params: 556,613\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 创建优化器等 \n",
    "model.compile(loss = \"categorical_crossentropy\",\n",
    "              opentimizer = 'adam', metrics = ['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "272/272 [==============================] - 37s 135ms/step - loss: 1.2501 - accuracy: 0.4899 - val_loss: 0.7201 - val_accuracy: 0.6029\n",
      "Epoch 2/100\n",
      "272/272 [==============================] - 32s 117ms/step - loss: 0.9114 - accuracy: 0.7188 - val_loss: 0.7717 - val_accuracy: 0.8824\n",
      "Epoch 3/100\n",
      "272/272 [==============================] - 22s 82ms/step - loss: 0.8593 - accuracy: 0.7868 - val_loss: 0.6484 - val_accuracy: 0.8235\n",
      "Epoch 4/100\n",
      "272/272 [==============================] - 19s 68ms/step - loss: 0.7415 - accuracy: 0.8199 - val_loss: 0.4608 - val_accuracy: 0.8676\n",
      "Epoch 5/100\n",
      "272/272 [==============================] - 18s 68ms/step - loss: 0.7614 - accuracy: 0.8346 - val_loss: 0.3859 - val_accuracy: 0.8382\n",
      "Epoch 6/100\n",
      "272/272 [==============================] - 35s 128ms/step - loss: 0.8018 - accuracy: 0.8300 - val_loss: 0.4750 - val_accuracy: 0.8971\n",
      "Epoch 7/100\n",
      "272/272 [==============================] - 23s 84ms/step - loss: 0.6677 - accuracy: 0.8410 - val_loss: 0.5093 - val_accuracy: 0.8235\n",
      "Epoch 8/100\n",
      "272/272 [==============================] - 18s 68ms/step - loss: 0.6470 - accuracy: 0.8566 - val_loss: 1.2750 - val_accuracy: 0.7353\n",
      "Epoch 9/100\n",
      "272/272 [==============================] - 33s 122ms/step - loss: 0.7578 - accuracy: 0.8493 - val_loss: 0.7029 - val_accuracy: 0.8971\n",
      "Epoch 10/100\n",
      "272/272 [==============================] - 16s 58ms/step - loss: 0.6084 - accuracy: 0.8676 - val_loss: 0.2695 - val_accuracy: 0.8676\n",
      "Epoch 11/100\n",
      "272/272 [==============================] - 13s 46ms/step - loss: 0.5345 - accuracy: 0.8612 - val_loss: 0.2202 - val_accuracy: 0.9412\n",
      "Epoch 12/100\n",
      "272/272 [==============================] - 12s 44ms/step - loss: 0.5522 - accuracy: 0.8860 - val_loss: 0.3245 - val_accuracy: 0.9118\n",
      "Epoch 13/100\n",
      "272/272 [==============================] - 12s 44ms/step - loss: 0.5196 - accuracy: 0.8667 - val_loss: 0.3568 - val_accuracy: 0.8971\n",
      "Epoch 14/100\n",
      "272/272 [==============================] - 14s 51ms/step - loss: 0.5349 - accuracy: 0.8851 - val_loss: 0.2652 - val_accuracy: 0.9412\n",
      "Epoch 15/100\n",
      "272/272 [==============================] - 13s 48ms/step - loss: 0.4848 - accuracy: 0.8778 - val_loss: 0.3904 - val_accuracy: 0.9265\n",
      "Epoch 16/100\n",
      "272/272 [==============================] - 13s 48ms/step - loss: 0.4804 - accuracy: 0.8906 - val_loss: 0.2921 - val_accuracy: 0.9118\n",
      "Epoch 17/100\n",
      "272/272 [==============================] - 14s 50ms/step - loss: 0.4945 - accuracy: 0.8814 - val_loss: 0.4565 - val_accuracy: 0.8824\n",
      "Epoch 18/100\n",
      "272/272 [==============================] - 13s 49ms/step - loss: 0.5279 - accuracy: 0.8971 - val_loss: 0.4316 - val_accuracy: 0.8824\n",
      "Epoch 19/100\n",
      "272/272 [==============================] - 12s 43ms/step - loss: 0.5598 - accuracy: 0.8713 - val_loss: 0.3086 - val_accuracy: 0.9118\n",
      "Epoch 20/100\n",
      "272/272 [==============================] - 12s 44ms/step - loss: 0.4912 - accuracy: 0.8860 - val_loss: 0.3319 - val_accuracy: 0.9118\n",
      "Epoch 21/100\n",
      "272/272 [==============================] - 12s 44ms/step - loss: 0.5095 - accuracy: 0.8934 - val_loss: 0.2248 - val_accuracy: 0.9559\n",
      "Epoch 22/100\n",
      "272/272 [==============================] - 12s 44ms/step - loss: 0.4748 - accuracy: 0.8925 - val_loss: 0.5189 - val_accuracy: 0.8971\n",
      "Epoch 23/100\n",
      "272/272 [==============================] - 12s 44ms/step - loss: 0.5246 - accuracy: 0.8934 - val_loss: 0.3449 - val_accuracy: 0.9265\n",
      "Epoch 24/100\n",
      "272/272 [==============================] - 12s 45ms/step - loss: 0.4608 - accuracy: 0.9090 - val_loss: 0.4519 - val_accuracy: 0.9118\n",
      "Epoch 25/100\n",
      "272/272 [==============================] - 12s 43ms/step - loss: 0.5494 - accuracy: 0.8879 - val_loss: 3.2602 - val_accuracy: 0.5882\n",
      "Epoch 26/100\n",
      "272/272 [==============================] - 12s 44ms/step - loss: 0.5753 - accuracy: 0.8952 - val_loss: 1.0288 - val_accuracy: 0.8971\n",
      "Epoch 27/100\n",
      "272/272 [==============================] - 12s 43ms/step - loss: 0.6138 - accuracy: 0.8989 - val_loss: 0.5898 - val_accuracy: 0.9118\n",
      "Epoch 28/100\n",
      "272/272 [==============================] - 12s 44ms/step - loss: 0.5746 - accuracy: 0.8814 - val_loss: 0.2657 - val_accuracy: 0.9265\n",
      "Epoch 29/100\n",
      "272/272 [==============================] - 12s 43ms/step - loss: 0.4929 - accuracy: 0.9053 - val_loss: 0.7694 - val_accuracy: 0.9412\n",
      "Epoch 30/100\n",
      "272/272 [==============================] - 12s 45ms/step - loss: 0.5565 - accuracy: 0.8934 - val_loss: 0.5426 - val_accuracy: 0.9118\n",
      "Epoch 31/100\n",
      "272/272 [==============================] - 12s 44ms/step - loss: 0.5508 - accuracy: 0.8842 - val_loss: 0.3644 - val_accuracy: 0.8971\n",
      "Epoch 32/100\n",
      "272/272 [==============================] - 12s 43ms/step - loss: 0.5706 - accuracy: 0.8943 - val_loss: 0.3303 - val_accuracy: 0.9412\n",
      "Epoch 33/100\n",
      "272/272 [==============================] - 12s 44ms/step - loss: 0.6011 - accuracy: 0.9017 - val_loss: 0.9608 - val_accuracy: 0.8235\n",
      "Epoch 34/100\n",
      "272/272 [==============================] - 12s 43ms/step - loss: 0.5152 - accuracy: 0.9035 - val_loss: 0.1848 - val_accuracy: 0.9559\n",
      "Epoch 35/100\n",
      "272/272 [==============================] - 12s 44ms/step - loss: 1.0595 - accuracy: 0.8869 - val_loss: 0.4646 - val_accuracy: 0.8971\n",
      "Epoch 36/100\n",
      "272/272 [==============================] - 12s 45ms/step - loss: 0.8556 - accuracy: 0.8778 - val_loss: 0.9677 - val_accuracy: 0.9412\n",
      "Epoch 37/100\n",
      "272/272 [==============================] - 12s 44ms/step - loss: 0.6701 - accuracy: 0.8934 - val_loss: 0.3480 - val_accuracy: 0.9118\n",
      "Epoch 38/100\n",
      "272/272 [==============================] - 12s 46ms/step - loss: 0.8051 - accuracy: 0.8796 - val_loss: 0.4710 - val_accuracy: 0.9559\n",
      "Epoch 39/100\n",
      "272/272 [==============================] - 12s 45ms/step - loss: 0.6813 - accuracy: 0.8833 - val_loss: 0.5099 - val_accuracy: 0.8971\n",
      "Epoch 40/100\n",
      "272/272 [==============================] - 12s 43ms/step - loss: 0.6605 - accuracy: 0.8943 - val_loss: 0.6272 - val_accuracy: 0.8971\n",
      "Epoch 41/100\n",
      "272/272 [==============================] - 12s 45ms/step - loss: 0.6816 - accuracy: 0.8888 - val_loss: 0.4265 - val_accuracy: 0.9265\n",
      "Epoch 42/100\n",
      "272/272 [==============================] - 12s 45ms/step - loss: 0.5772 - accuracy: 0.8998 - val_loss: 0.2207 - val_accuracy: 0.9559\n",
      "Epoch 43/100\n",
      "272/272 [==============================] - 12s 43ms/step - loss: 0.6365 - accuracy: 0.8961 - val_loss: 0.3676 - val_accuracy: 0.9412\n",
      "Epoch 44/100\n",
      "272/272 [==============================] - 12s 45ms/step - loss: 0.5125 - accuracy: 0.9118 - val_loss: 1.1809 - val_accuracy: 0.8824\n",
      "Epoch 45/100\n",
      "272/272 [==============================] - 12s 44ms/step - loss: 0.5808 - accuracy: 0.9099 - val_loss: 0.6634 - val_accuracy: 0.9265\n",
      "Epoch 46/100\n",
      "272/272 [==============================] - 12s 43ms/step - loss: 0.8166 - accuracy: 0.8787 - val_loss: 0.5384 - val_accuracy: 0.9118\n",
      "Epoch 47/100\n",
      "272/272 [==============================] - 12s 44ms/step - loss: 0.6422 - accuracy: 0.8980 - val_loss: 0.1270 - val_accuracy: 0.9706\n",
      "Epoch 48/100\n",
      "272/272 [==============================] - 12s 43ms/step - loss: 0.6858 - accuracy: 0.9026 - val_loss: 1.0002 - val_accuracy: 0.8824\n",
      "Epoch 49/100\n",
      "272/272 [==============================] - 12s 44ms/step - loss: 0.7651 - accuracy: 0.8860 - val_loss: 1.2191 - val_accuracy: 0.8824\n",
      "Epoch 50/100\n",
      "272/272 [==============================] - 12s 44ms/step - loss: 0.8456 - accuracy: 0.9007 - val_loss: 0.9187 - val_accuracy: 0.8824\n",
      "Epoch 51/100\n",
      "272/272 [==============================] - 12s 44ms/step - loss: 0.6500 - accuracy: 0.8814 - val_loss: 0.8470 - val_accuracy: 0.8971\n",
      "Epoch 52/100\n",
      "272/272 [==============================] - 12s 44ms/step - loss: 0.7698 - accuracy: 0.8980 - val_loss: 0.5101 - val_accuracy: 0.9412\n",
      "Epoch 53/100\n",
      "272/272 [==============================] - 12s 43ms/step - loss: 0.7952 - accuracy: 0.8989 - val_loss: 0.8598 - val_accuracy: 0.9118\n",
      "Epoch 54/100\n",
      "272/272 [==============================] - 12s 43ms/step - loss: 0.7808 - accuracy: 0.8897 - val_loss: 0.2867 - val_accuracy: 0.9265\n",
      "Epoch 55/100\n",
      "272/272 [==============================] - 12s 43ms/step - loss: 0.5407 - accuracy: 0.9062 - val_loss: 0.7576 - val_accuracy: 0.8971\n",
      "Epoch 56/100\n",
      "272/272 [==============================] - 12s 45ms/step - loss: 0.5680 - accuracy: 0.8961 - val_loss: 0.5167 - val_accuracy: 0.9118\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "272/272 [==============================] - 12s 45ms/step - loss: 0.6743 - accuracy: 0.8934 - val_loss: 1.1132 - val_accuracy: 0.8529\n",
      "Epoch 58/100\n",
      "272/272 [==============================] - 12s 46ms/step - loss: 0.5410 - accuracy: 0.9081 - val_loss: 0.4612 - val_accuracy: 0.9265\n",
      "Epoch 59/100\n",
      "272/272 [==============================] - 12s 46ms/step - loss: 0.6995 - accuracy: 0.8961 - val_loss: 0.8849 - val_accuracy: 0.8971\n",
      "Epoch 60/100\n",
      "272/272 [==============================] - 12s 43ms/step - loss: 1.1958 - accuracy: 0.8649 - val_loss: 0.4503 - val_accuracy: 0.9265\n",
      "Epoch 61/100\n",
      "272/272 [==============================] - 12s 44ms/step - loss: 0.4674 - accuracy: 0.9053 - val_loss: 0.4870 - val_accuracy: 0.9265\n",
      "Epoch 62/100\n",
      "272/272 [==============================] - 12s 43ms/step - loss: 0.6617 - accuracy: 0.9053 - val_loss: 0.4739 - val_accuracy: 0.9118\n",
      "Epoch 63/100\n",
      "272/272 [==============================] - 12s 45ms/step - loss: 0.5554 - accuracy: 0.9035 - val_loss: 0.3521 - val_accuracy: 0.9412\n",
      "Epoch 64/100\n",
      "272/272 [==============================] - 11s 42ms/step - loss: 0.6183 - accuracy: 0.8934 - val_loss: 0.4656 - val_accuracy: 0.9118\n",
      "Epoch 65/100\n",
      "272/272 [==============================] - 12s 44ms/step - loss: 0.5752 - accuracy: 0.9219 - val_loss: 1.1159 - val_accuracy: 0.8382\n",
      "Epoch 66/100\n",
      "272/272 [==============================] - 12s 44ms/step - loss: 0.7040 - accuracy: 0.8897 - val_loss: 1.2125 - val_accuracy: 0.8529\n",
      "Epoch 67/100\n",
      "272/272 [==============================] - 12s 43ms/step - loss: 0.6037 - accuracy: 0.9145 - val_loss: 0.5319 - val_accuracy: 0.9265\n",
      "Epoch 68/100\n",
      "272/272 [==============================] - 12s 43ms/step - loss: 0.6777 - accuracy: 0.9017 - val_loss: 0.4713 - val_accuracy: 0.9118\n",
      "Epoch 69/100\n",
      "272/272 [==============================] - 12s 44ms/step - loss: 0.8812 - accuracy: 0.8998 - val_loss: 0.5608 - val_accuracy: 0.9265\n",
      "Epoch 70/100\n",
      "272/272 [==============================] - 12s 44ms/step - loss: 0.6227 - accuracy: 0.9090 - val_loss: 0.3772 - val_accuracy: 0.8971\n",
      "Epoch 71/100\n",
      "272/272 [==============================] - 12s 45ms/step - loss: 0.8315 - accuracy: 0.9053 - val_loss: 0.5306 - val_accuracy: 0.8382\n",
      "Epoch 72/100\n",
      "272/272 [==============================] - 12s 42ms/step - loss: 0.6256 - accuracy: 0.8980 - val_loss: 0.7917 - val_accuracy: 0.9265\n",
      "Epoch 73/100\n",
      "272/272 [==============================] - 12s 44ms/step - loss: 0.5522 - accuracy: 0.9081 - val_loss: 0.3545 - val_accuracy: 0.9412\n",
      "Epoch 74/100\n",
      "272/272 [==============================] - 12s 44ms/step - loss: 0.7833 - accuracy: 0.8796 - val_loss: 0.6670 - val_accuracy: 0.8824\n",
      "Epoch 75/100\n",
      "272/272 [==============================] - 12s 46ms/step - loss: 0.5821 - accuracy: 0.9007 - val_loss: 0.7201 - val_accuracy: 0.8824\n",
      "Epoch 76/100\n",
      "272/272 [==============================] - 13s 47ms/step - loss: 0.7487 - accuracy: 0.8998 - val_loss: 1.0186 - val_accuracy: 0.8824\n",
      "Epoch 77/100\n",
      "272/272 [==============================] - 13s 47ms/step - loss: 0.7629 - accuracy: 0.8952 - val_loss: 0.5957 - val_accuracy: 0.9118\n",
      "Epoch 78/100\n",
      "272/272 [==============================] - 12s 44ms/step - loss: 1.3086 - accuracy: 0.8741 - val_loss: 0.9320 - val_accuracy: 0.9118\n",
      "Epoch 79/100\n",
      "272/272 [==============================] - 13s 47ms/step - loss: 0.7013 - accuracy: 0.8998 - val_loss: 0.7453 - val_accuracy: 0.9412\n",
      "Epoch 80/100\n",
      "272/272 [==============================] - 12s 43ms/step - loss: 0.8555 - accuracy: 0.9007 - val_loss: 1.0317 - val_accuracy: 0.8971\n",
      "Epoch 81/100\n",
      "272/272 [==============================] - 12s 45ms/step - loss: 1.0057 - accuracy: 0.8925 - val_loss: 0.5148 - val_accuracy: 0.9559\n",
      "Epoch 82/100\n",
      "272/272 [==============================] - 12s 44ms/step - loss: 0.9557 - accuracy: 0.8768 - val_loss: 0.3147 - val_accuracy: 0.9118\n",
      "Epoch 83/100\n",
      "272/272 [==============================] - 12s 44ms/step - loss: 0.9301 - accuracy: 0.8814 - val_loss: 0.2805 - val_accuracy: 0.9706\n",
      "Epoch 84/100\n",
      "272/272 [==============================] - 12s 45ms/step - loss: 0.8486 - accuracy: 0.8989 - val_loss: 0.3571 - val_accuracy: 0.9265\n",
      "Epoch 85/100\n",
      "272/272 [==============================] - 12s 45ms/step - loss: 1.4807 - accuracy: 0.8621 - val_loss: 9.8760 - val_accuracy: 0.3529\n",
      "Epoch 86/100\n",
      "272/272 [==============================] - 11s 42ms/step - loss: 1.0428 - accuracy: 0.8906 - val_loss: 0.8458 - val_accuracy: 0.8824\n",
      "Epoch 87/100\n",
      "272/272 [==============================] - 13s 48ms/step - loss: 0.9140 - accuracy: 0.8925 - val_loss: 1.5779 - val_accuracy: 0.8529\n",
      "Epoch 88/100\n",
      "272/272 [==============================] - 12s 43ms/step - loss: 1.0787 - accuracy: 0.8842 - val_loss: 0.2113 - val_accuracy: 0.9265\n",
      "Epoch 89/100\n",
      "272/272 [==============================] - 12s 45ms/step - loss: 1.1512 - accuracy: 0.8925 - val_loss: 1.0202 - val_accuracy: 0.9118\n",
      "Epoch 90/100\n",
      "272/272 [==============================] - 12s 44ms/step - loss: 1.7173 - accuracy: 0.8603 - val_loss: 1.7078 - val_accuracy: 0.8676\n",
      "Epoch 91/100\n",
      "272/272 [==============================] - 12s 46ms/step - loss: 1.3181 - accuracy: 0.8869 - val_loss: 0.8222 - val_accuracy: 0.9118\n",
      "Epoch 92/100\n",
      "272/272 [==============================] - 12s 44ms/step - loss: 0.8156 - accuracy: 0.9164 - val_loss: 1.7043 - val_accuracy: 0.8676\n",
      "Epoch 93/100\n",
      "272/272 [==============================] - 13s 46ms/step - loss: 1.1677 - accuracy: 0.9173 - val_loss: 1.7779 - val_accuracy: 0.8676\n",
      "Epoch 94/100\n",
      "272/272 [==============================] - 12s 44ms/step - loss: 1.4487 - accuracy: 0.8879 - val_loss: 4.3541 - val_accuracy: 0.7206\n",
      "Epoch 95/100\n",
      "272/272 [==============================] - 12s 46ms/step - loss: 1.6296 - accuracy: 0.8658 - val_loss: 0.3464 - val_accuracy: 0.9118\n",
      "Epoch 96/100\n",
      "272/272 [==============================] - 12s 46ms/step - loss: 1.1531 - accuracy: 0.9017 - val_loss: 3.1582 - val_accuracy: 0.7794\n",
      "Epoch 97/100\n",
      "272/272 [==============================] - 14s 51ms/step - loss: 1.1465 - accuracy: 0.9007 - val_loss: 0.3058 - val_accuracy: 0.9412\n",
      "Epoch 98/100\n",
      "272/272 [==============================] - 12s 44ms/step - loss: 1.3705 - accuracy: 0.8796 - val_loss: 0.3999 - val_accuracy: 0.9412\n",
      "Epoch 99/100\n",
      "272/272 [==============================] - 13s 46ms/step - loss: 1.5827 - accuracy: 0.8741 - val_loss: 0.8545 - val_accuracy: 0.9412\n",
      "Epoch 100/100\n",
      "272/272 [==============================] - 12s 43ms/step - loss: 2.8563 - accuracy: 0.8162 - val_loss: 7.1109 - val_accuracy: 0.5588\n"
     ]
    }
   ],
   "source": [
    "# 训练\n",
    "history = model.fit_generator(train_ds,\n",
    "                              steps_per_epoch= num_train // BATCH_SIZE,\n",
    "                              epochs= epochs,\n",
    "                              validation_data=val_ds,\n",
    "                              validation_steps= num_valid // BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
